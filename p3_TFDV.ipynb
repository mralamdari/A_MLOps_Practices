{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/A_MLOps_Practives/blob/main/p3_TFDV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 –-version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5M0m11_rAssv",
        "outputId": "704778a1-a4dc-419a-9064-46e34e134693"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/–-version': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CGchAVAqrsrZ",
        "outputId": "6e5eaf72-f214-48cb-eb24-460da21c818a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python3: can't open file '/content/–version': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-data-validation\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "devkJBi5GO3e",
        "outputId": "4ea1c068-22be-4a84-9a98-dbe0061c6a5e"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-bdaa84993841>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclear_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_data_validation\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfdv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_data_validation'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tempfile, urllib, zipfile\n",
        "from IPython.display import clear_output\n",
        "import tensorflow_data_validation as tfdv\n",
        "\n",
        "\n",
        "from tensorflow.python.lib.io import file_io\n",
        "from tensorflow_data_validation.utils import slicing_util\n",
        "from tensorflow_metadata.proto.v0.statistics_pb2 import DatasetFeatureStatisticsList, DatasetFeatureStatistics\n",
        "\n",
        "# Set TF's logger to only display errors to avoid internal warnings being shown\n",
        "tf.get_logger().setLevel('ERROR')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKnZP8xXNBtn",
        "outputId": "81c6fb53-df96-43f7-90bb-15bbb93a7c80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVLt1NSGpVex"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_data_validation as tfdv\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from util import add_extra_rows\n",
        "\n",
        "from tensorflow_metadata.proto.v0 import schema_pb2\n",
        "\n",
        "print('TFDV Version: {}'.format(tfdv.__version__))\n",
        "print('Tensorflow Version: {}'.format(tf.__version__))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKsl4v9kompD"
      },
      "outputs": [],
      "source": [
        "https://archive.ics.uci.edu/static/public/296/diabetes+130-us+hospitals+for+years+1999-2008.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-WlUxWtffuH"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('data/diabetic_data.csv', header=0, na_values = '?')\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tO24Xtgfj3B"
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "def prepare_data_splits_from_dataframe(df):\n",
        "    '''\n",
        "    Splits a Pandas Dataframe into training, evaluation and serving sets.\n",
        "\n",
        "    Parameters:\n",
        "            df : pandas dataframe to split\n",
        "\n",
        "    Returns:\n",
        "            train_df: Training dataframe(70% of the entire dataset)\n",
        "            eval_df: Evaluation dataframe (15% of the entire dataset)\n",
        "            serving_df: Serving dataframe (15% of the entire dataset, label column dropped)\n",
        "    '''\n",
        "\n",
        "    # 70% of records for generating the training set\n",
        "    train_len = int(len(df) * 0.7)\n",
        "\n",
        "    # Remaining 30% of records for generating the evaluation and serving sets\n",
        "    eval_serv_len = len(df) - train_len\n",
        "\n",
        "    # Half of the 30%, which makes up 15% of total records, for generating the evaluation set\n",
        "    eval_len = eval_serv_len // 2\n",
        "\n",
        "    # Remaining 15% of total records for generating the serving set\n",
        "    serv_len = eval_serv_len - eval_len\n",
        "\n",
        "    # Split the dataframe into the three subsets\n",
        "    train_df = df.iloc[:train_len].reset_index(drop=True)\n",
        "    eval_df = df.iloc[train_len: train_len + eval_len].reset_index(drop=True)\n",
        "    serving_df = df.iloc[train_len + eval_len: train_len + eval_len + serv_len].reset_index(drop=True)\n",
        "\n",
        "    # Serving data emulates the data that would be submitted for predictions, so it should not have the label column.\n",
        "    serving_df = serving_df.drop(['readmitted'], axis=1)\n",
        "\n",
        "    return train_df, eval_df, serving_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3wq-GhwgTcG"
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Split the datasets\n",
        "train_df, eval_df, serving_df = prepare_data_splits_from_dataframe(df)\n",
        "\n",
        "print('Training dataset has {} records\\nValidation dataset has {} records\\nServing dataset has {} records'.format(len(train_df),len(eval_df),len(serving_df)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Fol2Gu0gZzY"
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Define features to remove\n",
        "features_to_remove = {'encounter_id', 'patient_nbr'}\n",
        "\n",
        "# Collect features to include while computing the statistics\n",
        "approved_cols = [col for col in df.columns if (col not in features_to_remove)]\n",
        "\n",
        "# Instantiate a StatsOptions class and define the feature_allowlist property\n",
        "stats_options = tfdv.StatsOptions(feature_allowlist=approved_cols)\n",
        "\n",
        "# Review the features to generate the statistics\n",
        "for feature in stats_options.feature_allowlist:\n",
        "    print(feature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Uc5kzZ7gZwx"
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "train_stats = tfdv.generate_statistics_from_dataframe(train_df, stats_options)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2G2zttCliRuc"
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# TEST CODE\n",
        "\n",
        "# get the number of features used to compute statistics\n",
        "print(f\"Number of features used: {len(train_stats.datasets[0].features)}\")\n",
        "\n",
        "# check the number of examples used\n",
        "print(f\"Number of examples used: {train_stats.datasets[0].num_examples}\")\n",
        "\n",
        "# check the column names of the first and last feature\n",
        "print(f\"First feature: {train_stats.datasets[0].features[0].path.step[0]}\")\n",
        "print(f\"Last feature: {train_stats.datasets[0].features[-1].path.step[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEhTvkK-iTHc"
      },
      "outputs": [],
      "source": [
        "tfdv.visualize_statistics(train_stats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrMFaDnougta"
      },
      "outputs": [],
      "source": [
        "# Infer the data schema by using the training statistics that you generated\n",
        "schema = tfdv.infer_schema(statistics=train_stats)\n",
        "\n",
        "# Display the data schema\n",
        "tfdv.display_schema(schema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeHAuRr_vChE"
      },
      "outputs": [],
      "source": [
        "# Check number of features\n",
        "print(f\"Number of features in schema: {len(schema.feature)}\")\n",
        "\n",
        "# Check domain name of 2nd feature\n",
        "print(f\"Second feature in schema: {list(schema.feature)[1].domain}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEl_RmBJvCeX"
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Generate evaluation dataset statistics\n",
        "# HINT: Remember to use the evaluation dataframe and to pass the stats_options (that you defined before) as an argument\n",
        "eval_stats = tfdv.generate_statistics_from_dataframe(eval_df)\n",
        "# Compare evaluation data with training data\n",
        "# HINT: Remember to use both the evaluation and training statistics with the lhs_statistics and rhs_statistics arguments\n",
        "# HINT: Assign the names of 'EVAL_DATASET' and 'TRAIN_DATASET' to the lhs and rhs protocols\n",
        "\n",
        "tfdv.visualize_statistics(lhs_statistics=eval_stats,\n",
        "                          rhs_statistics=train_stats,\n",
        "                          lhs_name='EVAL_DATASET',\n",
        "                          rhs_name='TRAIN_DATASET')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkX5f-OJvCbi"
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# get the number of features used to compute statistics\n",
        "print(f\"Number of features: {len(eval_stats.datasets[0].features)}\")\n",
        "\n",
        "# check the number of examples used\n",
        "print(f\"Number of examples: {eval_stats.datasets[0].num_examples}\")\n",
        "\n",
        "# check the column names of the first and last feature\n",
        "print(f\"First feature: {eval_stats.datasets[0].features[0].path.step[0]}\")\n",
        "print(f\"Last feature: {eval_stats.datasets[0].features[-1].path.step[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6j_L2BzS0_Lq"
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "def calculate_and_display_anomalies(statistics, schema):\n",
        "    '''\n",
        "    Calculate and display anomalies.\n",
        "\n",
        "            Parameters:\n",
        "                    statistics : Data statistics in statistics_pb2.DatasetFeatureStatisticsList format\n",
        "                    schema : Data schema in schema_pb2.Schema format\n",
        "\n",
        "            Returns:\n",
        "                    display of calculated anomalies\n",
        "    '''\n",
        "    ### START CODE HERE\n",
        "    # HINTS: Pass the statistics and schema parameters into the validation function\n",
        "    anomalies = tfdv.validate_statistics(statistics=eval_stats, schema=schema)\n",
        "\n",
        "    # HINTS: Display input anomalies by using the calculated anomalies\n",
        "    tfdv.display_anomalies(anomalies)\n",
        "\n",
        "calculate_and_display_anomalies(eval_stats, schema=schema)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8W2U3Kq5zB6"
      },
      "source": [
        "Exercise 6: Fix evaluation anomalies in the schema\n",
        "The evaluation data has records with values for the features glimepiride-pioglitazone and medical_speciality that were not included in the schema generated from the training data. You can fix this by adding the new values that exist in the evaluation dataset to the domain of these features.\n",
        "\n",
        "To get the domain of a particular feature you can use tfdv.get_domain()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlOVUy3P0_I3"
      },
      "outputs": [],
      "source": [
        "# Get the domain associated with the input feature, glimepiride-pioglitazone, from the schema\n",
        "glimepiride_pioglitazone_domain = tfdv.get_domain(schema, 'glimepiride-pioglitazone')\n",
        "\n",
        "# HINT: Append the missing value 'Steady' to the domain\n",
        "glimepiride_pioglitazone_domain.value.append('Steady')\n",
        "\n",
        "# Get the domain associated with the input feature, medical_specialty, from the schema\n",
        "medical_specialty_domain = tfdv.get_domain(schema, 'medical_specialty')\n",
        "\n",
        "# HINT: Append the missing value 'Neurophysiology' to the domain\n",
        "medical_specialty_domain.value.append('Neurophysiology')\n",
        "\n",
        "# HINT: Re-calculate and re-display anomalies with the new schema\n",
        "calculate_and_display_anomalies(eval_stats, schema=schema)\n",
        "### END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28gwQujl0_Dd"
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Define a new statistics options by the tfdv.StatsOptions class for the serving data by passing the previously inferred schema\n",
        "options = tfdv.StatsOptions(schema=schema,\n",
        "                            infer_type_from_schema=True,\n",
        "                            feature_allowlist=approved_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2pTRZL08UeR"
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Generate serving dataset statistics\n",
        "# HINT: Remember to use the serving dataframe and to pass the newly defined statistics options\n",
        "serving_stats = tfdv.generate_statistics_from_dataframe(serving_df)\n",
        "\n",
        "# HINT: Calculate and display anomalies using the generated serving statistics\n",
        "calculate_and_display_anomalies(serving_stats, schema=schema)\n",
        "### END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVseYZWe8Ubk"
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# This relaxes the minimum fraction of values that must come from the domain for the feature.\n",
        "\n",
        "# Get the feature and relax to match 90% of the domain\n",
        "payer_code = tfdv.get_feature(schema, 'payer_code')\n",
        "payer_code.distribution_constraints.min_domain_mass = 0.9\n",
        "\n",
        "# Get the feature and relax to match 90% of the domain\n",
        "medical_specialty = tfdv.get_feature(schema, 'medical_specialty')\n",
        "medical_specialty.distribution_constraints.min_domain_mass = 0.9\n",
        "\n",
        "# Detect anomalies with the updated constraints\n",
        "calculate_and_display_anomalies(serving_stats, schema=schema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ln88-ljH88j9"
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "tfdv.display_schema(schema)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INiH0D5UA2Ph"
      },
      "source": [
        "Towards the bottom of the Domain-Values pairs of the cell above, you can see that many features (including 'metformin') have the same values: ['Down', 'No', 'Steady', 'Up']. These values are common to many features including the ones with missing values during schema inference.\n",
        "\n",
        "TFDV allows you to modify the domains of some features to match an existing domain. To address the detected anomaly, you can set the domain of these features to the domain of the metformin feature.\n",
        "\n",
        "Complete the function below to set the domain of a feature list to an existing feature domain.\n",
        "\n",
        "For this, use the tfdv.set_domain() function, which has the following parameters:\n",
        "\n",
        "schema: The schema\n",
        "feature_path: The name of the feature whose domain needs to be set.\n",
        "domain: A domain protocol buffer or the name of a global string domain present in the input schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "661LG7A088hQ"
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "def modify_domain_of_features(features_list, schema, to_domain_name):\n",
        "    '''\n",
        "    Modify a list of features' domains.\n",
        "\n",
        "            Parameters:\n",
        "                    features_list : Features that need to be modified\n",
        "                    schema: Inferred schema\n",
        "                    to_domain_name : Target domain to be transferred to the features list\n",
        "\n",
        "            Returns:\n",
        "                    schema: new schema\n",
        "    '''\n",
        "    ### START CODE HERE\n",
        "    # HINT: Loop over the feature list and use set_domain with the inferred schema, feature name and target domain name\n",
        "    for feature in features_list:\n",
        "        tfdv.set_domain(schema, feature, to_domain_name)\n",
        "    return schema\n",
        "\n",
        "# grader-required-cell\n",
        "\n",
        "domain_change_features = ['repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride',\n",
        "                          'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone',\n",
        "                          'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone', 'tolazamide',\n",
        "                          'examide', 'citoglipton', 'insulin', 'glyburide-metformin', 'glipizide-metformin',\n",
        "                          'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone']\n",
        "\n",
        "\n",
        "# Infer new schema by using your modify_domain_of_features function\n",
        "# and the defined domain_change_features feature list\n",
        "schema = modify_domain_of_features(domain_change_features, schema, 'metformin')\n",
        "\n",
        "# Display new schema\n",
        "tfdv.display_schema(schema)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqxK81RiCcqGE3BtWsmNLw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}