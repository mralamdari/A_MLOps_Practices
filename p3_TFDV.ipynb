{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgWidHWHnVhyaj9F0ujIo8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/A_MLOps_Practives/blob/main/p3_TFDV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "# grader-required-cell\n",
        "\n",
        "# Import packages\n",
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tempfile, urllib, zipfile\n",
        "import tensorflow_data_validation as tfdv\n",
        "\n",
        "\n",
        "from tensorflow.python.lib.io import file_io\n",
        "from tensorflow_data_validation.utils import slicing_util\n",
        "from tensorflow_metadata.proto.v0.statistics_pb2 import DatasetFeatureStatisticsList, DatasetFeatureStatistics\n",
        "\n",
        "# Set TF's logger to only display errors to avoid internal warnings being shown\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "metadata": {
        "id": "devkJBi5GO3e"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-data-validation\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "CGchAVAqrsrZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKnZP8xXNBtn",
        "outputId": "81c6fb53-df96-43f7-90bb-15bbb93a7c80"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_data_validation as tfdv\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from util import add_extra_rows\n",
        "\n",
        "from tensorflow_metadata.proto.v0 import schema_pb2\n",
        "\n",
        "print('TFDV Version: {}'.format(tfdv.__version__))\n",
        "print('Tensorflow Version: {}'.format(tf.__version__))"
      ],
      "metadata": {
        "id": "DVLt1NSGpVex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKsl4v9kompD"
      },
      "outputs": [],
      "source": [
        "https://archive.ics.uci.edu/static/public/296/diabetes+130-us+hospitals+for+years+1999-2008.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('data/diabetic_data.csv', header=0, na_values = '?')\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "p-WlUxWtffuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "def prepare_data_splits_from_dataframe(df):\n",
        "    '''\n",
        "    Splits a Pandas Dataframe into training, evaluation and serving sets.\n",
        "\n",
        "    Parameters:\n",
        "            df : pandas dataframe to split\n",
        "\n",
        "    Returns:\n",
        "            train_df: Training dataframe(70% of the entire dataset)\n",
        "            eval_df: Evaluation dataframe (15% of the entire dataset)\n",
        "            serving_df: Serving dataframe (15% of the entire dataset, label column dropped)\n",
        "    '''\n",
        "\n",
        "    # 70% of records for generating the training set\n",
        "    train_len = int(len(df) * 0.7)\n",
        "\n",
        "    # Remaining 30% of records for generating the evaluation and serving sets\n",
        "    eval_serv_len = len(df) - train_len\n",
        "\n",
        "    # Half of the 30%, which makes up 15% of total records, for generating the evaluation set\n",
        "    eval_len = eval_serv_len // 2\n",
        "\n",
        "    # Remaining 15% of total records for generating the serving set\n",
        "    serv_len = eval_serv_len - eval_len\n",
        "\n",
        "    # Split the dataframe into the three subsets\n",
        "    train_df = df.iloc[:train_len].reset_index(drop=True)\n",
        "    eval_df = df.iloc[train_len: train_len + eval_len].reset_index(drop=True)\n",
        "    serving_df = df.iloc[train_len + eval_len: train_len + eval_len + serv_len].reset_index(drop=True)\n",
        "\n",
        "    # Serving data emulates the data that would be submitted for predictions, so it should not have the label column.\n",
        "    serving_df = serving_df.drop(['readmitted'], axis=1)\n",
        "\n",
        "    return train_df, eval_df, serving_df"
      ],
      "metadata": {
        "id": "5tO24Xtgfj3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Split the datasets\n",
        "train_df, eval_df, serving_df = prepare_data_splits_from_dataframe(df)\n",
        "print('Training dataset has {} records\\nValidation dataset has {} records\\nServing dataset has {} records'.format(len(train_df),len(eval_df),len(serving_df)))"
      ],
      "metadata": {
        "id": "w3wq-GhwgTcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Define features to remove\n",
        "features_to_remove = {'encounter_id', 'patient_nbr'}\n",
        "\n",
        "# Collect features to include while computing the statistics\n",
        "approved_cols = [col for col in df.columns if (col not in features_to_remove)]\n",
        "\n",
        "# Instantiate a StatsOptions class and define the feature_allowlist property\n",
        "stats_options = tfdv.StatsOptions(feature_allowlist=approved_cols)\n",
        "\n",
        "# Review the features to generate the statistics\n",
        "for feature in stats_options.feature_allowlist:\n",
        "    print(feature)"
      ],
      "metadata": {
        "id": "6Fol2Gu0gZzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "### START CODE HERE\n",
        "train_stats = tfdv.generate_statistics_from_dataframe(train_df)\n",
        "### END CODE HERE"
      ],
      "metadata": {
        "id": "8Uc5kzZ7gZwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# TEST CODE\n",
        "\n",
        "# get the number of features used to compute statistics\n",
        "print(f\"Number of features used: {len(train_stats.datasets[0].features)}\")\n",
        "\n",
        "# check the number of examples used\n",
        "print(f\"Number of examples used: {train_stats.datasets[0].num_examples}\")\n",
        "\n",
        "# check the column names of the first and last feature\n",
        "print(f\"First feature: {train_stats.datasets[0].features[0].path.step[0]}\")\n",
        "print(f\"Last feature: {train_stats.datasets[0].features[-1].path.step[0]}\")"
      ],
      "metadata": {
        "id": "2G2zttCliRuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfdv.visualize_statistics(train_stats)\n"
      ],
      "metadata": {
        "id": "OEhTvkK-iTHc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}